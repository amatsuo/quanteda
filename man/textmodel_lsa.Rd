% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/textmodel_lsa.R
\name{textmodel_lsa}
\alias{textmodel_lsa}
\alias{textmodel_lsa}
\alias{transform_lsa}
\title{Latent Semantic Analysis}
\usage{
textmodel_lsa(x, nd = 10)

textmodel_lsa(x, nd = 10)

transform_lsa(newX, LSAspace)
}
\arguments{
\item{x}{the matrix on which the model will be fit}

\item{nd}{Number of dimensions to be included in output.}

\item{newX}{new matrix to be transformed into the lsa space}

\item{LSAspace}{previously fitted lsa space}
}
\description{
\code{textmodel_lsa} implements Latent Semantic Analysis scaling on a matrix, which can be a dfm or a tfidf.
}
\details{
\link[RSpectra]{svds} in the \pkg{RSpectra} package is applied to 
  enable the fast computation of the SVD.
}
\note{
The number of dimensions \code{nd} retained in LSA is an empirical issue. While a reduction in k can remove much of the noise, keeping too few dimensions
 or factors may loose important information.
}
\examples{
ieDfm <- dfm(data_corpus_irishbudget2010)
# create an LSA space and return its truncated representation in the low-rank space
mylsa <- textmodel_lsa(ieDfm[1:10, ])
head(mylsa$docs)

# fold querys into the space generated by ieDfm[1:10,]
# and return its truncated versions of its representation in the new low-rank space
newlsa <- transform_lsa(ieDfm[11:14, ], mylsa)
newlsa$transDocs

}
\references{
Barbara Rosario.  2000. "Latent Semantic Indexing: An overview". 
\emph{Techn. rep. INFOSYS 240 Spring Paper, University of California, Berkeley.} 
\url{http://www.sims.berkeley.edu/rosario/projects/LSI.pdf}
}
\author{
Haiyan Wang and Kenneth Benoit
}
