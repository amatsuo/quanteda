% Generated by roxygen2 (4.0.2): do not edit by hand
\name{compoundWords}
\alias{compoundWords}
\title{convert phrases into single tokens}
\usage{
compoundWords(txts, dictionary, connector = "_")
}
\arguments{
\item{txts}{character or character vector of texts}

\item{dictionary}{a list or named list (such as a quanteda dictionary) that
contains some phrases, defined as multiple words delimited by whitespace.
These can be up to 9 words long.}

\item{connector}{the concatenation character that will connect the words
making up the multi-word phrases.  The default \code{_} is highly
recommended since it will not be removed during normal cleaning and
tokenization (while nearly all other punctuation characters, at least those
in the POSIX class \code{[[:punct:]]}) will be removed.}
}
\value{
character or character vector of texts with phrases replaced by
  compound "words" joined by the connector
}
\description{
Replace multi-word phrases in text(s) with a compound version of the phrases
concatenated with  \code{connector} (by default, the "\code{_}" character) to
form a single token.  This prevents tokenization of the phrases during
subsequent processing by eliminating the whitespace delimiter.
}
\examples{
mytexts <- c("The new law included a capital gains tax, and an inheritance tax.",
             "New York City has raised a taxes: an income tax and a sales tax.")
mydict <- list(tax=c("tax", "income tax", "capital gains tax", "inheritance tax"))
(cw <- compoundWords(mytexts, mydict))
print(dfm(cw), show.values=TRUE)

# when used as a dictionary for dfm creation
mydfm2 <- dfm(cw, dictionary=lapply(mydict, function(x) gsub(" ", "_", x)))
print(mydfm2, show.values=TRUE)
# to pick up "taxes" in the second text, set regular_expression=TRUE
mydfm3 <- dfm(cw, dictionary=lapply(mydict, function(x) gsub(" ", "_", x)),
              dictionary_regex=TRUE)
print(mydfm3, show.values=TRUE)
}

