% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/findSequences.R
\name{findSequences}
\alias{findSequences}
\title{find sequences of tokens}
\usage{
findSequences(x, tokens, count_min = 2, len_max = 5, smooth = 0.001)
}
\description{
This function automatically identify sequences of tokens. This algorithm is   
based on Blaheta and Johnson's “Unsupervised Learning of Multi-Word Verbs”.
}
\examples{
data(SOTUCorpus, package = "quantedaData")
sents <- tokenize(SOTUCorpus, what='sentence', simplify = TRUE)
tokens <- tokenize(sents, removePunct = TRUE)
types <- unique(unlist(tokens))

# Extracting multi-part nouns
types_upper <- types[stringi::stri_detect_regex(types, "^([A-Z][a-z\\\\-]{2,})")]
findSequences(tokens, types_upper, count_min=2)

# Types can be any words
types_lower <- types[stri_detect_regex(types, "^([a-z]+)$") & !types \%in\%stopwords()]
findSequences(tokens, types_lower, count_min=2)
}

