% Generated by roxygen2 (4.0.2): do not edit by hand
\name{dfms}
\alias{dfms}
\alias{dfms.character}
\alias{dfms.corpus}
\title{create a sparse document-feature matrix}
\usage{
dfms(x, ...)

\method{dfms}{character}(x, verbose = TRUE, clean = TRUE, stem = FALSE,
  removestopwords = FALSE, dense = FALSE, language = "english",
  fromCorpus = FALSE, ...)

\method{dfms}{corpus}(x, verbose = TRUE, clean = TRUE, stem = FALSE,
  removestopwords = FALSE, dense = FALSE, language = "english",
  groups = NULL, ...)
}
\arguments{
\item{x}{corpus or character vector from which to generate the document-feature matrix}

\item{...}{additional arguments passed to \code{\link{clean}}}

\item{verbose}{display messages if \code{TRUE}}

\item{clean}{if \code{FALSE}, do no cleaning of the text}

\item{stem}{if \code{TRUE}, stem words}

\item{removestopwords}{if \code{TRUE}, remove stopwords in \code{langage}}

\item{dense}{if \code{TRUE}, produce a dense matrix, otherwise produce a
sparse matrix of class \code{dgCMatrix} from the \pkg{\link{Matrix}}
package.}

\item{language}{Language for stemming and stopwords.  Choices are
\code{danish, dutch, english, finnish, french, german, hungarian, italian,
norwegian, porter, portuguese, romanian, russian, spanish, swedish,
turkish} for stemming, and \code{SMART, danish, english, french, hungarian,
norwegian, russian, swedish, catalan, dutch, finnish, german, italian,
portuguese, spanish, arabic} for stopwords.}

\item{groups}{Grouping variable for aggregating documents}
}
\value{
A specially classed \link[Matrix]{Matrix} object with row names equal
  to the document names and column names equal to the feature labels.
}
\description{
Create a sparse matrix dfm from a corpus or a vector of texts, using the
\pkg{Matrix} package.  This is both much faster and much more memory efficient
than the regular (dense) \link{dfm} object.
}
\details{
Eventually the plan is to represent all dfm's as sparse matrixes.
}
\examples{
# with inaugural texts
dfmsInaug <- dfms(inaugTexts)
(size1 <- object.size(dfmsInaug))
(size2 <- object.size(dfm(inaugTexts)))
cat("Compacted by ", round(as.numeric((1-size1/size2)*100), 1), "\%.\\n", sep="")

\dontrun{
# try it with approx 35,000 court documents from Lauderdale and Clark (200?)
load('~/Dropbox/QUANTESS/Manuscripts/Collocations/Corpora/lauderdaleClark/Opinion_files.RData')
txts <- unlist(Opinion_files[1])
names(txts) <- NULL

# dfms without cleaning
require(Matrix)
system.time(dfmsBig <- dfms(txts, clean=FALSE, verbose=FALSE))
object.size(dfmsBig)
dim(dfmsBig)
# compare with tm
require(tm)
tmcorp <- VCorpus(VectorSource(txts))
system.time(tmDTM <- DocumentTermMatrix(tmcorp))
object.size(tmDTM)
dim(tmDTM)

# with cleaning - the gsub() calls in clean() take a long time
system.time(dfmsBig <- dfms(txts, clean=TRUE, additional="[-_\\\\x{h2014}]"))
object.size(dfmsBig)
dim(dfmsBig)
# 100 top features
topf <- colSums(dfmsBig)
names(topf) <- colnames(dfmsBig)
head(sort(topf, decreasing=TRUE), 100)
}
# sparse matrix from a corpus
mydfms <- dfms(inaugCorpus)
data(iebudgetsCorpus, package="quantedaData")
mydfms2 <- dfms(SOTUCorpus, groups = c("name", "party"))
}
\author{
Kenneth Benoit
}

