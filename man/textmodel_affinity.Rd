% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/textmodel_affinity.R
\name{textmodel_affinity}
\alias{textmodel_affinity}
\title{Class affinity maximum likelihood text scaling model}
\usage{
textmodel_affinity(x, y, exclude = NULL, smooth = 0.5, ref_smooth = 0.5,
  verbose = FALSE)
}
\arguments{
\item{x}{the \link{dfm} or \link{bootstrap_dfm} object on which the model
will be fit.  Does not need to contain only the training documents, since
the index of these will be matched automatically.}

\item{y}{vector of training classes/scores associated with each document
identified in \code{data}}

\item{exclude}{a set of words to exclude from the model}

\item{smooth}{a smoothing parameter for class affinities; defaults to 0.5
(Jeffreys prior). A plausible alternative would be 1.0 (Laplace prior).}

\item{ref_smooth}{a smoothing parameter for token distributions;
defaults to 0.5}

\item{verbose}{logical; if \code{TRUE} print diagnostic information during
fitting.}
}
\description{
\code{textmodel_affinity} implements the maximum likelihood supervised text
scaling method described in Perry and Benoit (2017).
}
\examples{
(fitted <- textmodel_affinity(data_dfm_lbgexample, y = c("L", NA, NA, NA, "R", NA)))
predict(fitted)
predict(fitted, newdata = data_dfm_lbgexample[6, ])

\dontrun{
# compute bootstrapped SEs
bsdfm <- bootstrap_dfm(data_corpus_dailnoconf1991, n = 10, remove_punct = TRUE)
textmodel_affinity(bsdfm, y = c("Govt", "Opp", "Opp", rep(NA, 55)))
}
}
\references{
Perry, Patrick O. and Kenneth Benoit.  (2017) "Scaling Text with
  the Class Affinity Model".
  \href{http://arxiv.org/abs/1710.08963}{arXiv:1710.08963 [stat.ML]}.
}
\author{
Patrick Perry
}
\keyword{experimental}
\keyword{textmodel}
