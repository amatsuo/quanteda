% Generated by roxygen2 (4.1.0): do not edit by hand
% Please edit documentation in R/tokenize.R
\name{tokenizeOnlyCpp}
\alias{tokenizeOnlyCpp}
\alias{tokenizeOnlyScan}
\title{tokenize only functions}
\usage{
tokenizeOnlyCpp(x, sep = " ")

tokenizeOnlyScan(x, sep = " ")
}
\arguments{
\item{x}{text(s) to be tokenized}

\item{sep}{separator delineating tokens}
}
\description{
For performance comparisons.  \code{tokenizeOnlyCpp} calls Kohei's C++ code,
without cleaning, while \code{tokenizeOnlyScan} calls \code{\link{scan}}.
Both functions use \code{\link{lapply}} to return a list of tokenized texts,
when \code{x} is a vector of texts.
}
\examples{
\donttest{load('~/Dropbox/QUANTESS/Manuscripts/Collocations/Corpora/lauderdaleClark/Opinion_files.RData')
txts <- unlist(Opinion_files[1])
names(txts) <- NULL
system.time(tmp1 <- tokenizeOnlyCpp(txts))
## about 9.2 seconds on Ken's MacBook Pro
system.time(tmp2 <- tokenizeOnlyScan(txts))
## about 13.8 seconds
}
}

