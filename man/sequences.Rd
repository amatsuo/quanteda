% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sequences.R
\name{sequences}
\alias{sequences}
\title{find sequences of tokens}
\usage{
sequences(x, features, valuetype = c("glob", "regex", "fixed"),
  case_insensitive = TRUE, count_min = 2, nested = TRUE, ...)
}
\arguments{
\item{x}{tokens objects}

\item{features}{features in sequences}

\item{count_min}{minimum frequency of sequences}

\item{nested}{collect nested sequences}
}
\description{
This function automatically identify sequences of words (contiguous collocations). 
This algorithm is based on Blaheta and Johnson's “Unsupervised Learning of Multi-Word Verbs”.
}
\examples{

toks <- tokens(corpus_segment(data_corpus_inaugural, what = "sentence"), removePunct = TRUE)
toks <- tokens_select(toks, stopwords("english"), "remove", padding = TRUE)

# extracting multi-part nouns
seqs <- sequences(toks, "^([A-Z][a-z\\\\-]{2,})", valuetype="regex", case_insensitive = FALSE)
head(seqs, 10)

# types can be any words
seqs2 <- sequences(toks, "^([a-z]+)$", valuetype="regex", case_insensitive = FALSE, count_min = 10)
head(seqs2, 10)

}
\author{
Kohei Watanabe
}
\references{
Blaheta, D., & Johnson, M. (2001). Unsupervised learning of
  multi-word verbs. Presented at the ACLEACL Workshop on the Computational
  Extraction, Analysis and Exploitation of Collocations.
}
\keyword{collocations}

