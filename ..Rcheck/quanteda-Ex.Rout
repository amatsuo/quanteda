
R version 3.1.1 (2014-07-10) -- "Sock it to Me"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "quanteda"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('quanteda')
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("MCMCirtPoisson1d")
> ### * MCMCirtPoisson1d
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: MCMCirtPoisson1d
> ### Title: Bayesian-MCMC version of a 1-dimensional Poisson IRT scaling
> ###   model
> ### Aliases: MCMCirtPoisson1d
> 
> ### ** Examples
> 
> ## Not run: 
> ##D data(iebudgets)
> ##D # extract just the 2010 debates
> ##D iebudgets2010 <- subset(iebudgets, year==2010)
> ##D 
> ##D # create a document-term matrix and set the word margin to the columns
> ##D dtm <- dfm(iebudgets2010)
> ##D 
> ##D # estimate the maximium likelihood wordfish model from austin
> ##D require(austin)
> ##D iebudgets2010_wordfish <- wordfish(as.wfm(dtm, word.margin=2), dir=c(2,1))
> ##D 
> ##D # estimate the MCMC model, default values
> ##D iebudgets2010_wordfishMCMC <- MCMCirtPoisson1d(dtm, itembase="the", dir=c(2,1))
> ##D iebudgets2010_wordfishMCMC_unconstrained <- MCMCirtPoisson1d(dtm, dir=c(2,1))
> ##D 
> ##D # compare the estimates of \eqn{\theta_i}
> ##D require(psych)
> ##D pairs.panels(data.frame(ML=iebudgets2010_wordfish$theta,
> ##D                         PoissonThe=iebudgets2010_wordfishMCMC$theta,
> ##D                         PoissonUnconst=iebudgets2010_wordfishMCMC_unconstrained$theta),
> ##D              smooth=FALSE, scale=FALSE, ellipses=FALSE, lm=TRUE, cex.cor=2.5)
> ##D # inspect a known "opposition" word beta values
> ##D iebudgets2010_wordfish$beta[which(iebudgets2010_wordfishMCMC_unconstrained$words=="fianna")]
> ##D iebudgets2010_wordfishMCMC$beta[which(iebudgets2010_wordfishMCMC_unconstrained$words=="fianna")]
> ##D iebudgets2010_wordfishMCMC_unconstrained$beta[which(iebudgets2010_wordfishMCMC_unconstrained$words=="fianna")]
> ##D 
> ##D # random starting values, for three chains
> ##D dtm.sample <- trim(dtm, sample=200)
> ##D iebudgets2010_wordfishMCMC_sample <- MCMCirtPoisson1d(dtm.sample, dir=c(2,1), startRandom=TRUE, nChains=3)
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("bigrams")
> ### * bigrams
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: bigrams
> ### Title: Create bigrams
> ### Aliases: bigrams
> 
> ### ** Examples
> 
> bigrams("The quick brown fox jumped over the lazy dog.")
[1] "the_quick"   "quick_brown" "brown_fox"   "fox_jumped"  "jumped_over"
[6] "over_the"    "the_lazy"    "lazy_dog."  
> bigrams("The quick brown fox jumped over the lazy dog.", window=2)
 [1] "the_quick"    "quick_brown"  "brown_fox"    "fox_jumped"   "jumped_over" 
 [6] "over_the"     "the_lazy"     "lazy_dog."    "the_brown"    "quick_fox"   
[11] "brown_jumped" "fox_over"     "jumped_the"   "over_lazy"    "the_dog."    
> 
> 
> 
> cleanEx()
> nameEx("collocations")
> ### * collocations
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: collocations
> ### Title: Detect collocations in a text
> ### Aliases: collocations
> 
> ### ** Examples
> 
> data(inaugCorpus)
> collocations(texts(inaugCorpus)[1], top=50)
Loading required package: entropy
             collocation Freq        lr
269       country, whose    1 10.714221
334  established without    1 10.714221
381       first official    1 10.714221
872           rules over    1 10.714221
1206  whose providential    1 10.714221
1207         whose voice    1 10.714221
50       american people    1  9.669331
230          citizens at    1  9.669331
339          event could    1  9.669331
372      fellow citizens    1  9.669331
682            nor those    1  9.669331
903           some share    1  9.669331
1064         their union    1  9.669331
1069      themselves too    1  9.669331
1148       union between    1  9.669331
1205           who rules    1  9.669331
1233        without some    1  9.669331
445             has been    2  8.991343
686          not without    1  8.991343
747            one hand,    1  8.991343
884       sentiments not    1  8.991343
895          since there    1  8.991343
922           such being    1  8.991343
1167           was first    1  8.991343
1168        was rendered    1  8.991343
184         between duty    1  8.626049
1065        their united    1  8.626049
1072           there are    1  8.626049
333     established than    1  8.487609
340            event has    1  8.487609
504    impressions under    1  8.487609
582            less than    2  8.487609
898               so his    1  8.487609
404        from official    1  8.086509
552          is rendered    1  8.086509
179            being who    1  7.949670
193              but not    1  7.949670
263            could not    1  7.949670
566         its citizens    1  7.949670
684              not but    1  7.949670
685             not less    1  7.949670
750              one who    1  7.949670
1237             you are    1  7.949670
169     been established    1  7.753227
238     communities from    1  7.753227
450            have been    5  7.753227
274             day more    1  7.468145
535       influence your    1  7.468145
672             no event    1  7.468145
767            over this    1  7.468145
> collocations(texts(inaugCorpus)[1], top=50, method="chi2")
                 collocation Freq chi2
1       (inheriting inferior    1 1248
17          accordingly pray    1 1248
21       actual expenditures    1 1248
34  advantageously promoted.    1 1248
37  affectionate sensibility    1 1248
39                again give    1 1248
49                 am placed    1 1248
110              ardent love    1 1248
111         arduous struggle    1 1248
115              arising out    1 1248
138   auspiciously commence.    1 1248
182            benign parent    1 1248
192                brings us    1 1248
217          carefully avoid    1 1248
218             cares before    1 1248
220    characteristic rights    1 1248
221      characters selected    1 1248
232    civil administration)    1 1248
242         concerns myself,    1 1248
252     considered, perhaps,    1 1248
256   constitutional charter    1 1248
281          declining years    1 1248
306     distrustful scrutiny    1 1248
307          divine blessing    1 1248
317    effective government,    1 1248
325          enlarged views,    1 1248
329                equal eye    1 1248
330      equally conspicuous    1 1248
332      essential purposes,    1 1248
362     experiment entrusted    1 1248
365           faithful study    1 1248
375    fervent supplications    1 1248
378          finally, staked    1 1248
382        flattering hopes,    1 1248
383    fondest predilection,    1 1248
392   foregoing observations    1 1248
400   frequent interruptions    1 1248
407       functions allotted    1 1248
411           genuine maxims    1 1248
412                 give way    1 1248
413              given birth    1 1248
427            gradual waste    1 1248
428     grateful remembrance    1 1248
429         gratitude, along    1 1248
433        greater anxieties    1 1248
436               had chosen    1 1248
457              having thus    1 1248
471 honorable qualifications    1 1248
502     important revolution    1 1248
503    impregnably fortified    1 1248
> 
> 
> 
> cleanEx()

detaching ‘package:entropy’

> nameEx("corpus.character")
> ### * corpus.character
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: corpus.character
> ### Title: This function creates a corpus from a character vector (of
> ###   texts), adds text-specific variables (which we term "attributes"),
> ###   along with optional meta-data and notes.
> ### Aliases: corpus.character
> 
> ### ** Examples
> 
> data(inaugTexts)
> corpus(inaugTexts)
[1] "Texts (first 5): \n"
[1] "Fellow-Citizens of the Senate and of the House of Representatives:\n\nAmong the vicissitudes incident  ...."
[2] "Fellow citizens, I am again called upon by the voice of my country to execute the functions of its C ...."  
[3] "When it was first perceived, in early times, that no middle course for America remained between unli ...."  
[4] "Friends and Fellow Citizens:\n\nCalled upon to undertake the duties of the first executive office of o ...."
[5] "Proceeding, fellow citizens, to that qualification which the Constitution requires before my entranc ...."  
[1] "Attributes: \n"
> 
> 
> 
> cleanEx()
> nameEx("countSyllables")
> ### * countSyllables
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: countSyllables
> ### Title: Returns a count of the number of syllables in the input This
> ###   function takes a text and returns a count of the number of syllables
> ###   it contains. For British English words, the syllable count is exact
> ###   and looked up from the CMU pronunciation dictionary. For any word not
> ###   in the dictionary the syllable count is estimated by counting vowel
> ###   clusters.
> ### Aliases: countSyllables
> 
> ### ** Examples
> 
> countSyllables("This is an example sentence.")
This is an example sentence. 
                           9 
> myTexts <- c("Text one.", "Superduper text number two.", "One more for the road.")
> names(myTexts) <- paste("myText", 1:3, sep="")
> countSyllables(myTexts)
myText1 myText2 myText3 
      3       8       6 
> 
> 
> 
> cleanEx()
> nameEx("describeTexts")
> ### * describeTexts
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: describeTexts
> ### Title: print a summary of texts Prints to the console a desription of
> ###   the texts, including number of types, tokens, and sentences
> ### Aliases: describeTexts
> 
> ### ** Examples
> 
> texts <- c("testing this text", "and this one")
> describeTexts(texts)
  Texts Types Tokens Sentences
1 text1     3      3         1
2 text2     3      3         1
  Texts Types Tokens Sentences
1 text1     3      3         1
2 text2     3      3         1
> 
> 
> 
> cleanEx()
> nameEx("dfm")
> ### * dfm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: dfm
> ### Title: Create a document-feature matrix from a corpus object
> ### Aliases: dfm dfm.character dfm.corpus
> 
> ### ** Examples
> 
> data(inaugCorpus)
> wfm <- dfm(inaugCorpus)
Creating dfm from a corpus: ...  done. 
> 
> ## by president, after 1960
> wfmByPres2010 <- dfm(subset(inaugCorpus, year>1960), groups="president")
Creating dfm from a corpus: ... aggregating by group: president... complete ... done. 
> 
> ## with dictionaries
> corpus <- subset(inaugCorpus, year>1960)
> mydict <- list(christmas=c("Christmas", "Santa", "holiday"),
+                opposition=c("Opposition", "reject", "notincorpus"),
+                taxing="taxing",
+                taxation="taxation",
+                taxregex="tax*")
> dictDfm <- dfm(corpus, dictionary=mydict)
Creating dfm from a corpus: ...  done. 
> dictDfm
                  words
docs               christmas opposition taxing taxation taxregex Non_Dictionary
  1961-Kennedy.txt         0          0      0        0        0           1373
  1965-Johnson.txt         0          1      0        0        0           1451
  1969-Nixon.txt           1          0      0        0        0           2075
  1973-Nixon.txt           0          0      0        0        0           1816
  1977-Carter.txt          0          1      0        0        0           1190
  1981-Reagan.txt          0          0      0        0        4           2355
  1985-Reagan.txt          0          0      0        0        6           2479
  1989-Bush.txt            0          1      0        0        0           2313
  1993-Clinton.txt         0          0      0        0        0           1570
  1997-Clinton.txt         0          0      0        0        0           2157
  2001-Bush.txt            0          0      0        0        1           1552
  2005-Bush.txt            0          0      0        0        0           2040
  2009-Obama.txt           0          1      0        0        0           2374
  2013-Obama.txt           0          1      0        0        1           2077
> 
> ## removing stopwords
> testText <- "The quick brown fox named Séamus jumps over the lazy dog Rory, with Tom's newpaper in his mouth."#
> testCorpus <- corpus(testText)
> dfm(testCorpus, stopwords=TRUE)
Creating dfm from a corpus: ...  removing stopwords ...  done. 
   brown      dog      fox    jumps     lazy   mouth.    named newpaper 
       1        1        1        1        1        1        1        1 
   quick    rory,   séamus    tom's 
       1        1        1        1 
> if (require(tm)) {
+ }
Loading required package: tm
Loading required package: NLP
NULL
> 
> ## adding one dfm to another
> mydict2 <- list(partyref=c("Lenihan", "Fianna", "Sinn", "Gael"))
> dictDfm2 <- dfm(corpus, dictionary=mydict2, addto=dictDfm)
Creating dfm from a corpus: ...  done. 
> dictDfm2
                  words
docs               christmas opposition taxing taxation taxregex partyref
  1961-Kennedy.txt         0          0      0        0        0        0
  1965-Johnson.txt         0          1      0        0        0        0
  1969-Nixon.txt           1          0      0        0        0        0
  1973-Nixon.txt           0          0      0        0        0        0
  1977-Carter.txt          0          1      0        0        0        0
  1981-Reagan.txt          0          0      0        0        4        0
  1985-Reagan.txt          0          0      0        0        6        0
  1989-Bush.txt            0          1      0        0        0        0
  1993-Clinton.txt         0          0      0        0        0        0
  1997-Clinton.txt         0          0      0        0        0        0
  2001-Bush.txt            0          0      0        0        1        0
  2005-Bush.txt            0          0      0        0        0        0
  2009-Obama.txt           0          1      0        0        0        0
  2013-Obama.txt           0          1      0        0        1        0
                  words
docs               Non_Dictionary
  1961-Kennedy.txt           1373
  1965-Johnson.txt           1451
  1969-Nixon.txt             2075
  1973-Nixon.txt             1816
  1977-Carter.txt            1190
  1981-Reagan.txt            2355
  1985-Reagan.txt            2479
  1989-Bush.txt              2313
  1993-Clinton.txt           1570
  1997-Clinton.txt           2157
  2001-Bush.txt              1552
  2005-Bush.txt              2040
  2009-Obama.txt             2374
  2013-Obama.txt             2077
> 
> 
> 
> cleanEx()

detaching ‘package:tm’, ‘package:NLP’

> nameEx("dfm2ldaformat")
> ### * dfm2ldaformat
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: dfm2ldaformat
> ### Title: Convert a quanteda 'dfm' (document feature matrix) into a the
> ###   data format needed by lda
> ### Aliases: dfm2ldaformat
> 
> ### ** Examples
> 
> data(inaugCorpus)
> inaugCorpus <- subset(inaugCorpus, year==2010)
> # create document-feature matrix, remove stopwords
> d <- dfm(inaugCorpus, stopwords=TRUE)
Creating dfm from a corpus: ...  removing stopwords ... Error in x[subset & !is.na(subset), vars, drop = drop] : 
  (subscript) logical subscript too long
Calls: dfm ... dfm -> dfm.character -> t -> subset -> subset.matrix
Execution halted
