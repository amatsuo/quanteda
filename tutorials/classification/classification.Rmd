# Statistcal Learning with Text

***

This document investigates properties of classification, regression and scaling techniques in R, using the `quanteda` library for corpus management.



## Text Regression in R

### Ridge regression

In the machine learning literature, supervised methods for estimating continuous values from data are generally known as regression models, irrespective of whether the estimation procedure used one of those familiar from social science statistics, such as ordinary least squares (OLS). 

Estimating a outcome variable from text-as-data is an example of a problem in which the number of parameters available (p) maybe be greater than the number of observations of the outcome variable (n). In the most simple case treating the frequency of each word as a variable and associating a single response variable with each document, the relation of `p` and `n` is described by Heap's law:

$$Vocab(n) ~ Kn^(\beta)$$


Ridge regression and wordscores:
```{r}
library(quanteda)

myinaug <- inaugCorpus

# response variable is years since declaration of independence
year <- as.numeric((docvars(inaugCorpus)$Year)) - 1789

# explanatory variable is word tfidf
wordtfidf <- tfidf(trimdfm(dfm(inaugCorpus, stopwords=TRUE, stem=TRUE), minCount=8, minDoc=4))
wordtfidf <- sort(wordtfidf)[,0:1000]

trainData <- data.nrow=0,ncol=1000
testData <- data.frame()
labels <- list()
# training set is every 8th documnt

trainData <- wordtfidf[seq(1, nrow(wordtfidf), 8),]
trainLabels <- year[seq(1, length(year), 8)]

library(glmnet)
elasticModel <- glmnet(trainData, trainLabels)

library(austin)
ws <- classic.wordscores(as.wfm(t(trainData)), trainLabels)
predRidge <- predict(elasticModel, wordtfidf)
predWs <- predict(ws, as.wfm(t(wordtfidf)))

plot(predWs$Score, predRidge[,10])
cor(predWs$Score, predRidge[,78])

```

Wordscores

```{r}

olsModel <- lm(year~wordtfidf)
elasticModel <- glmnet(wordtfidf, year)


```

