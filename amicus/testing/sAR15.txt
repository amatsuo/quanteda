The Court has considered challenges to race-conscious admissions in higher education on two previous occasions, in DeFunis v. Odegaard, 416 U.S. 312 (1974), and in Regents of the Univ. of Cal. v. Bakke, 438 U.S. 265 (1978). n2 In each case one Justice indicated that bias in testing or grading procedures might be sufficient reason to justify considering race during the admissions process. See Bakke, 438 U.S., at 306 n.43 (Powell, J., announcing judgment); DeFunis, 416 U.S., at 335 (Douglas, J., dissenting). In each case, the absence of evidence concerning such bias prevented the Court from addressing the issue. In the case below, however, extensive evidence was produced in pretrial and during the bench trial to demonstrate, as both opinions foresaw, the need to consider the applicant's race in order to ensure a fair and accurate  [*3]  appraisal of each applicant's academic promise in the light of some bias in grading or testing procedures. Indeed, as Justice Powell observed, "To the extent that race and ethnic background were considered only to the extent of curing established inaccuracies in predicting academic performance, it might be argued that there is no 'preference' at all." Bakke, 438 U.S., at 306 n.43. 

n2 The Court also considered standardized testing and discrimination in United States v. Fordice, 505 U.S. 717, 734-37 (1992) (in holding that Mississippi did not satisfy its obligation to dismantle de jure segregation in its public university system, the Court concluded that admission standards that required a minimum score on the ACT (American College Testing Program) "are not only traceable to the de jure system and were originally adopted for a discriminatory purpose, but they also have present discriminatory effects"). 

The National Center for Fair & Open Testing (FairTest) presents this brief as amicus curiae to aid the Court in understanding the implications of granting the relief Petitioner seeks--prohibiting the consideration of applicants' racial or ethnic background as a factor in understanding their admission test scores and application in light of the depth and breadth of racial and gender discrimination in this country's past and present. This brief reviews the evidence available in this case and places it in the context of the overall issue of admissions testing. This specific evidence and the general research on admissions testing indicate that norm-referenced multiple-choice admissions tests such as the SAT and LSAT reflect race in ways that school grades do not, and that both standardized tests such as the SAT and LSAT and undergraduate grade-point averages (GPA) may have the facade of objectivity merely by being "numbers", but all are further subject to significant errors of measurement. n3 

n3 Both the district court and the court of appeal below have acknowledged other compelling reasons for considering race as a factor in university admissions, such as the educational importance of diversity among each class of students, and remedying the history of societal discrimination and its impacts upon various students of color. Pet. App. at 189a, 193a-257a, 257a-292a, 137 F. Supp. 2d 821, 825-55, 855-72; Pet. App. at 1a, 288 F.3d 732. While FairTest finds these and other reasons compelling, in this brief it does not repeat the arguments demonstrating that those compelling reasons are consistent with the Equal Protection Clause of the Fourteenth Amendment and Title VI of the Civil Rights Act of 1964 (42 U.S.C. § 2000d). To aid the Court, FairTest here focuses solely upon the failure of standardized tests and standardized testing to provide the neutral, objective measure of "merit" which is at the center of Petitioner's equal protection analysis, and the need therefore to consider racial background as a compensating factor in order to accord equal treatment to students of color. 

 [*4]  Standardized tests and testing do not exist within a social vacuum. Law schools must be able to consider applicants' racial or ethnic background in order to compensate for the errors in test scores caused by cultural bias, stereotype threat, unequal access to test preparation, and even the test's own standard errors of measurement. The evidence in this trial indicates that many of these differences can be attributed to the manner in which such tests are constructed, creating a permanent disadvantage against minority groups of test takers who have traditionally scored lower on previous versions of the test. In addition, the negative stereotypes about the intellectual capabilities of disadvantaged minority group members adversely affect the most academically successful candidates from those groups during their performance on the admission test. 

a. By nature, the SAT and LSAT have standard errors of measurement, standard errors of difference, and weak correlations with what they purport to predict, i.e. first-year grades in college and law school, respectively. No one disputes these facts. These admission tests are not the precise, accurate measures of merit Petitioner's argument assumes. Equally important, the nature of test construction and item selection introduces both racial and gender biases that adversely affect students of color and women. Thus, the SAT and LSAT are not neutral, objective measures of "merit" either, for these biases fall upon minority and women applicants. Affirmative consideration of the applicant's race and gender is necessary in the admissions process in order to correct for these biases and treat applicants equally. 

 [*5]  b. Dr. Claude Steele, a professor of psychology at Stanford University, presented evidence that even the best efforts of test developers to reduce bias in the test will not produce a test that has race-neutral results until the most academically successful minority students are given an opportunity to dispel the negative stereotype through academic performance. Empirical studies by Professor Steele and his peers in the profession demonstrate that even the best efforts of test developers to reduce bias do not remove the bias against students of color on standardized tests due to "stereotype threat". Stereotype threat describes the phenomenon whereby academically successful minority students--who are most aware of and most sensitive to the negative stereotypes about minority students' "inferior" average performance on standardized tests, and are most anxious to avoid confirming the negative stereotype that their racial or ethnic group(s) possess less intellectual ability on such tests--succumb to that anxiety and perform below their ability resulting in artificially depressed test scores. E.g., Expert Report of Claude M. Steele, reprinted in 5 Mich. J. Race & L. 439, 447 (1999) (hereinafter Steele Expert Report). The evidence went unrefuted at trial and is widely accepted in the academic community. 

c. Not only are the admissions tests subject to internal biases and to external biases such as stereotype threat, but access to test preparation courses which improve test scores is biased and not equally available. 

Opponents of race-conscious admissions exploit significantly negative stereotypes through constant reference to the depressed test scores of minority students, often equating them with grades, or even omitting all reference to grades. Their solution is to exclude the most academically successful minority students in favor of white students with the same grades, but higher test scores. University efforts to enroll minority students with grades similar to their white  [*6]  counterparts are met with charges of reverse discrimination based on unequal test scores. But test scores do not equal "merit". Instead, the evidence below demonstrates that failure to correct the artificially depressed test scores of racial minorities with narrowly tailored race-conscious measures amounts to a failure to treat equally qualified students of all races as equals. 

ARGUMENT 

Tests in education gradually entered public consciousness beginning after World War II, partly in response to a substantial increase in the number of college applications due to the Gl Bill. Fifty years ago, people did not give much attention to standardized tests and testing. Today, standardized tests are ubiquitous. It is hard to imagine that it was ever otherwise. 

The gravamen of Petitioner's claim is that the University of Michigan Law School would have admitted her ahead of other minority applicants had it ranked her application only by scores on the Law School Admission Test (LSAT) and undergraduate grade-point averages, and not considered diversity as an additional factor. 1 Jt. App. 29 at 33-34 (Complaint PP19-23, 26); n4 Petitioner's Br. at 2 (citing GPA, LSAT scores as evidence of Petitioner's qualifications for admission). Petitioner argues that law schools may not consider diversity, through the individual applicants' race and other socioeconomic characteristics. To justify the argument, Petitioner asks the Court to accept the implicit corollary that standardized tests such as the SAT and the LSAT, per se and as applied, are neutral, accurate, and sufficient measures of an applicant's merit, such that Petitioner should have been admitted ahead of other minority applicants with lower  [*7]  numbers, and that factors such as the race of the applicant and test taker should not be considered. 

n4 "Pet. App." refers to the appendix filed August 9, 2002, with the petition for writ of certiorari. "Jt. App." refers to the joint appendix filed January 16, 2003. 

On the contrary, standardized tests, and standardized testing, are replete with elements of well-documented bias and errors of measurement, which Amicus Curiae FairTest summarizes below. In this context, to fail to consider the applicant's race--whether to promote diversity, or to remedy the history of discrimination found by the district court below, but at the very least to compensate for and correct the bias and error inherent in the other key factors considered such as undergraduate grade-point average and SAT or LSAT scores--would deny minority applicants equal treatment. This is not a case where a race-conscious admission policy is being used to admit less qualified candidates; instead, the race-conscious admission policy is being used to prevent unfair discrimination which would occur if admission decisions were based primarily on test scores. 

I. STANDARDIZED TESTS ARE NOT THE NEUTRAL, OBJECTIVE MEASURES OF "MERIT" THAT PETITIONER'S ARGUMENT ASSUMES. 

Petitioner's argument centers upon an admissions "index" that is a composite of an applicant's score on the Law School Admission Test and the applicant's undergraduate grade-point average (GPA). No one would presume to be able to describe a student's mind in a single word, or even a single sentence; but Petitioner's argument asks the Court to be assured that a test number for a White applicant, or Latina applicant, or Black applicant, can capture the student in a single number--that the LSAT is the standard for "merit" and, by implication, the calibrator for equal protection analysis. 

The SAT (formerly called the Scholastic Aptitude Test and later the Scholastic Assessment Test) is an admissions test, sponsored by the College Board and used by colleges and  [*8]  universities to make admission decisions. The SAT is purportedly designed to help predict students' first-year grades in college. Similarly, the LSAT is an admissions test, designed by the Law School Admission Council, used by law schools to make admissions decisions. The LSAT is purportedly designed to predict students' first-year grades in law school. In many cases, both are effectively gatekeepers of admissions to higher education and law schools. Both have admitted errors in measurement, and both have only modest correlation with what they purport to measure. Neither is the neutral, objective measure of "merit" that Petitioner's argument assumes. 

The standard error of measurement is a basic principle of test design, reflecting the fact that an examinee's observed score on any given test form varies from her or his "true score". Therefore, psychometricians use the concept of standard error of measurement, which is an estimate of how close the student's observed score is to the true score the student would receive if the test contained no error of measurement. An interval of two standard errors of measurement above and below the true score for a test-taker will include 95 percent of the test-taker's obtained scores on the form. William C. Kidder, Portia Denied: Unmasking Gender Bias on the LSAT and Its Relationship to Racial Diversity in Legal Education, 12 Yale J.L. & Feminism 1, 19 (2000). The College Board reports the standard error of measurement on the SAT. On the SAT I, one standard error of measurement is approximately plus or minus 30 points on the verbal section and approximately plus or minus 30 points on the math section, on a scale of 200-800 points, indicating that, on average, a test-taker's true score may vary in either direction by 30 points from her or his observed, reported scores. According to the College Board, SAT I verbal and math scores must each differ by at least 60 points in order to indicate any true differences of whatever the test measures  [*9]  (called the standard error of difference). Similarly, on the LSAT, the standard error measurement is plus or minus 2.6 points on a scale of 120-180 points, at a 67-percent confidence level, and plus or minus 5.2 points at the more commonly accepted 95-percent confidence level. Id., at 19. LSAT scores must differ by plus or minus 7.3 points in order to indicate true differences of ability with 95-percent confidence. Id., at 19-20. 

Both the SAT and LSAT also have weak correlation with what they purport to measure. The SAT explains only approximately 22 percent of the variation among applicants' first-year college grade-point averages; high school grades alone do a better job, explaining almost 30 percent of the variance in first-year college grades. n5 Jay Rosner provided expert testimony in the district court that the LSAT only explains 16-20 percent of the variation in first-year grades, leaving 80-84 percent of the variation unexplained by the LSAT. See Pet. App. at 268a, 137 F. Supp. 2d at 860. As the district court below found, "The evidence presented at trial indicated that the LSAT predicts law school grades rather poorly (with a correlation of only 10-20%) and that it does not predict success in the legal profession at all." Pet. App. at 288a, 137 F. Supp. 2d at 870. 

n5 The College Board claims that the verbal and math sections of the SAT have a correlation of .47 and .48, respectively, with first-year college grade-point average. These numbers are deceptive, however. To determine how much of the difference in students' first-year grades the SAT really predicts, one squares the College Board's correlation coefficients to obtain the correlation (called r-squared) between the SAT scores and the difference or variation among freshman grades. See, e.g., Expert Report of Martin Shapiro, reprinted in 12 Berkeley La Raza L.J. 387, 392-93 (2001) (hereinafter Shapiro Expert Report) (explaining methodology). 

 [*10]  Thus, the very designer of the LSAT, the Law School Admission Council, admitted in a report released to address those who imply that test scores equal "merit":
  
Classroom diversity and the benefits that it provides are threatened by legal challenges to affirmative action and by the increasing power of law school rankings to corrupt law school admission decision making. Both of these factors may promote test misuse, particularly overreliance on LSAT scores and undergraduate grades as proxies for merit. 
  
. . . Applicants with high test scores and grades are usually admitted to all but the most highly selective schools regardless of the other factors they may or may not bring to the mix. This practice has fostered an assumption that high scores and grades alone define merit and entitle admission. To understand and improve law school admission decision making in the current climate, there must be a far greater understanding of the value and limitations of the standard numerical predictors.
  
Law School Admission Council, The Art and Science of Law School Admission Decision Making 3 (Aug. 2002) (revision of Law School Admission Council, New Models to Assure Diversity, Fairness, and Appropriate Test Use in Law School Admissions (1999)). 

The expert testimony of Professor Claude Steele on this point went unrefuted. Prof. Steele is Chair of the Department of Psychology at Stanford University since 1997, and a Professor of Psychology since 1991. He has served as President of the Western Psychological Association, a Fellow of the American Psychological Association, and a member of the Board of Directors of the American Psychological Society, and on the editorial boards of numerous journals and study sections at both the National Institute of Mental Health  [*11]  and the National Institute of Alcoholism and Alcohol Abuse. His expert testimony in this case was based on his own 25 years of research in the areas of social psychology, the social psychology of race and race relations, and the effects of race on standardized test performance, as well as consultations with a broad range of colleagues and experts in these areas and a review of the research literature. Steele Expert Report, supra, 5 Mich. J. Race & L. at 439. 

As Professor Steele explains:
The SAT is popularly assumed to measure such a singularly important component of academic merit as to mandate its centrality in the admissions process. . . . In contrast to most people's expectations . . . the SAT in fact measures only about 18% (ranging from 7% to 30%) of the factors that determine a person's freshman grades. And this figure holds even when controlling for the difficulty of the courses taken. (It also holds when the statistical problem of restriction of range is controlled for.) Moreover, the SAT adds hardly any predictive power in the prediction of freshman grades over what one gets from using high school grades alone. That is, using the SAT only increases one's prediction of freshman grades by about 3% or 4% (ranging from 0% to 7%) over what one could predict using high school grades alone. And as the criterion measures get farther away in time from when the SAT is taken--as for sophomore grades, graduation rates, and professional success--the correlations with the SAT get substantially smaller. 

An important implication of this fact is that even large score differences on the SAT do not translate into very large differences in the skills that underlie grade performance. This is what is implied by the small relationship between scores on the test and subsequent grades: that relatively few of the skills critical to grades  [*12]  are measured by the tests. And this, in turn, means that a score difference between two people, or between two groups (for example, Blacks and Whites), that is as large as say, 300 points, a difference that can sound big, actually represents a very small difference in skills critical to grade performance.
  
Id., at 442-43. 

Professor Steele summarizes his expert opinion, this 25 years of research, and these consultations with colleagues and experts in the field:
Standardized admissions tests such as the SAT, the ACT, and the LSAT are of limited value in evaluating "merit" or determining admissions qualifications of all students, but particularly for African American, Hispanic, and American Indian applicants for whom systematic influences make these tests even less diagnostic of their scholastic potential. The first part of this caution--that the test should not be relied upon too heavily in general admissions--is a standard recommendation of the companies that produce these tests, but is also based on extensive evidence documenting the limited predictiveness of these tests. This is not surprising given that these tests are not designed to measure innate ability nor mastery of a specified curriculum. Instead, standardized tests measure developed skills.
  
Id., at 440. n6 

n6 See also James Blascovich, Steven J. Spencer, Diane M. Quinn & Claude M. Steele, African Americans and High Blood Pressure: The Role of Stereotype Threat, 12 Psychol. Sci. 225 (2001); Claude M. Steele, Thin Ice: "Stereotype Threat" and Black College Students, Atlantic Monthly, Aug. 1999, at 44; Claude M. Steele, A Threat in the Air: How Stereotypes Shape Intellectual Identity and Performance, 52 Am. Psychol. 613 (1997); Claude M. Steele & Joshua Aronson, Stereotype Threat and the Intellectual Test Performance of African Americans, 69 J. Personality & Soc. Psychol. 797 (1995), reprinted in The Black-White Test Score Gap 401 (Christopher Jencks & Meredith Philips eds., 1998). 

 [*13]  Petitioner's argument to calibrate the equal protection analysis against the apparent precision of the grid set forth on pages 7-8 of the petition for writ of certiorari is instead subject to standard errors of measurement and weak correlations with the differences among first-year grades the SAT and LSAT purport to explain. 

II. COMPENSATING FOR THE BIASES OF STANDARDIZED TESTS AND STANDARDIZED TESTING REQUIRES ADMISSIONS OFFICES TO CONSIDER RACE AS ONE FACTOR IN ORDER TO ENSURE EQUAL TREATMENT TO STUDENTS OF COLOR AND TO ASSESS EQUALLY THEIR TRUE PROMISE FOR ADMISSION. 

Petitioner argues that the University of Michigan Law School may not consider and promote the incoming class's diversity, through the individual applicants' race and other socioeconomic characteristics. n7 To justify the argument,  [*14]  Petitioner asks the Court to accept the implicit corollary, that standardized tests such as the SAT and the LSAT, per se and as applied, are neutral, accurate, and sufficient measures of an applicant's merit, such that Petitioner should have been admitted ahead of other minority applicants with lower "numbers", and that factors such as the race of the applicant and test taker should not be considered. On the contrary, standardized tests, and standardized testing, are not only replete with standard errors of measurement and poor correlation, but with elements of well-documented bias, which Amicus Curiae FairTest summarizes below. 

n7 Petitioner raises no objection to a law school's consideration of "legacy" or relationship to university alumni as an admissions factor, however, or other common factors. Pet. App. at 228a, 137 F. Supp. 2d at 841-42. Nor did Petitioner in her complaint offer to forego the gender-based affirmative action also found at the University of Michigan Law School, which compensates for gender bias in standardized tests and testing. Expert Report of Stephanie M. Wildman, reprinted in 12 Berkeley La Raza L.J. 429, 430 (2001) (hereinafter Wildman Expert Report). As Professor Shapiro testified, admissions offices consider a variety of demographic factors in making admissions decisions, such as "the representation of regions within a state or a country, the ratio of male and female applicants accepted, the racial or ethnic composition of the entering class, the alumni representation within the accepted students, the socioeconomic distribution of the accepted applicants, the sufficiency of athletic skills within the entering body, the ratio of public to private secondary school graduates within the entering student class, the percentage of students of a given religion among the accepted applicants, or the projected number of students who might select various academic majors. These considerations have had both exclusionary motives and inclusionary motives." Shapiro Expert Report, supra, 12 Berkeley La Raza L.J. at 395. 

Not only do the SAT and LSAT not measure "merit" (or they measure some aspect of merit no better than "poorly" n8), but they do measure race, bias, and the long, heart-breaking history of racial discrimination in education. n9 They measure racial bias through the internal design of the test, and they measure race and bias through external influences upon those students of color who take the tests. It  [*15]  is not only permissible but essential that institutions of higher education, such as the University of Michigan's Law School, consider explicitly and compensate for these elements of racial bias in their admissions processes, in order to ensure that all similarly situated applicants are treated equally as individuals. 

n8 As the district court found, "the LSAT predicts law school grades rather poorly (with a correlation of only 10-20%) and . . . it does not predict success in the legal profession at all." Pet. App. at 288a, 137 F. Supp. 2d at 870. 

n9 They also measure gender bias, and the equally heart-breaking history of gender discrimination in education. E.g. Expert Report of Stephanie M. Wildman, reprinted in 12 Berkeley La Raza L.J. 429 (2001); William C. Kidder, Portia Denied: Unmasking Gender Bias on the LSAT and Its Relationship to Racial Diversity in Legal Education, 12 Yale J.L. & Feminism 1 (2000); David K. Leonard & Jiming Jiang, Gender Bias and the College Predictions of the SAT: A Cry of Despair, 40 Research in Higher Educ. 375 (1999). 

A. Standard Internal Errors and Biases in Test Design and Item Selection 

The differences between grades and test scores first came to this Court's attention in the Bakke case, when the Law School Admission Council's brief displayed the national applicant pool to law schools according to undergraduate grade-point average, LSAT scores, and racial identity. Brief of Amicus Curiae Law School Admission Council in Regents of the Univ. of Cal. v. Bakke, 438 U.S. 265 (1978), reprinted in 4 Allan Bakke versus Regents of the University of California: The Supreme Court of the United States 143 (Alfred A. Slocum ed., 1978). The brief showed that GPAs and LSAT scores were equally distributed among White applicants, but not among Black or Hispanic/Latino applicants. Among Black and Hispanic/Latino applicants, there were many more candidates with higher grades than test scores. See Expert Report of David M. White, reprinted in 12 Berkeley La Raza L.J. 399, 404-05 (2001) (hereinafter White Expert Report). 

Similar evidence was produced at trial below. Racial gaps in LSAT scores remain even when students are closely matched on previous academic achievement. Controlling for other variables, individuals attending the same elite undergraduate institution, with the same undergraduate grade-point average, nonetheless produces gaps on the LSAT compared to White applicants: -4.0 points for Native Americans, -6.8 points for Hispanics, and -9.2 points for African-Americans. White Expert Report, supra, 12 Berkeley La Raza L.J. at 405-06, quoted in Pet. App. at 269a, 137 F.  [*16]  Supp. 2d at 861; see also William C. Kidder, Does the LSAT Mirror or Magnify Racial and Ethnic Differences in Educational Attainment?: A Study of Equally Achieving "Elite" College Students, 89 Cal. L. Rev. 1055, 1073-74 (2001). n10 

n10 Asian-Americans are often grouped together with Whites when assessing bias in standardized testing. E.g. Pet. App. at 277a, 137 F. Supp. 2d at 865 (indicating that Asian Americans were not "members of the underrepresented minority groups at issue in this case"). In fact, when one examines Asian-Americans by their separate "subgroups", and compares the scores on the LSAT of equally qualified Asian-American and White students (having equivalent grade-point averages at the same selective colleges), the results again show the bias, with Chinese students having -2.3 points below, Korean students having -2.4 points below, Japanese students having -2.8 points below, Southeast Asian students having -5.3 points below, and Filipino students having -5.5 points below. W. Kidder, supra, 89 Cal. L. Rev. at 1073-76. It is difficult to confirm similar bias on the SAT because the College Board does not publish annual data by subgroup, but overall, Asian Americans have scores -30 points below Whites on the verbal section, +35 points above Whites on the math section. William C. Kidder & Jay Rosner, How the SAT Creates "Built-In Headwinds": An Educational and Legal Analysis of Disparate Impact, 43 Santa Clara L. Rev. 131, 166-67 & nn. 127, 131 (2003). 

The discriminatory impact or reliance on test scores compared to grades is not limited to race. Women, too, are not well represented at the very top levels of LSAT scores, but women apply to law school with higher average GPAs than men. Wildman Expert Report, supra, 12 Berkeley La Raza L.J. at 430 (citing W. Kidder, supra, 12 Yale J.L. & Feminism at 19). Similarly, colleges encounter applicant pools with men outscoring women on the SAT, but enroll student bodies with women earning higher average grades than men. W. Kidder & J. Rosner, supra, 43 Santa Clara L. Rev. at 168. 

Racial bias and gender bias in standardized testing "overlap and interact", such that moderating racial item bias will  [*17]  simultaneously moderate gender item bias, and vice versa. Wildman Expert Report, supra, 12 Berkeley La Raza L.J. at 430; W. Kidder & J. Rosner, supra, 43 Santa Clara L. Rev. at 168-69 & nn. 138-142 (regarding SAT); W. Kidder, supra, 89 Cal. L. Rev. at 1103 & n.221 (regarding LSAT); W. Kidder, supra, 12 Yale J.L. & Feminism at 11-17 (regarding LSAT). 

These differences between grades and norm-referenced tests can be associated with their underlying components. The GPA cumulates individual grades from a variety of courses and instructors. Individual courses do not have to be correlated with each other, and while a student may be expected to do approximately the same in different courses, he or she may not delete a low grade just because it does not correlate with other higher grades. 

In developing a norm-referenced standardized test, in contrast, test questions are correlated with each other, and they are pre-tested and often eliminated when test takers do not perform on them in accordance with test specifications. Test questions cannot be evaluated to measure such characteristics as difficulty and bias until they are pretested as part of an official form of the test. (To measure those characteristics properly, the form may not identify the questions as experimental questions that will be excluded from the test score.) When scores on a pretest item do not display a sufficiently high correlation with previously administered items, the item is discarded or revised. Thus, a grade is part of the undergraduate GPA because it was earned at an accredited college that awarded credit for that course. An individual test item is on the test because it meets various content specifications and because it correlates positively with other test items--an internal circularity that introduces the potential bias. Shapiro Expert Report, supra, 12 Berkeley La Raza L.J. at 388-90; 8 Transcript, Feb. 6, 2001, at 29:10-17, 40:11-42:13 (Shapiro). 

 [*18]  When a norm-referenced multiple-choice test is pretested on a population including a small minority of test takers from a population that has traditionally performed poorly on the test, that small minority group can be perpetually disadvantaged. A small racial group participating in the pretest, which has previously posted lower average scores, will most likely see questions that disfavor them but favor the majority racial group included in the final version of the test, because the item will still have displayed a sufficiently high correlation among all test takers; but items that favor the small racial group but disfavor the majority racial group will generally be discarded, because the item will not display a sufficiently high correlation among all test takers. Shapiro Expert Report, supra, 12 Berkeley La Raza L.J. at 388-90; 8 Transcript, Feb. 6, 2001, at 48:5-49:12 (Shapiro). 

The items will be discarded not because they favor one or another racial group, but because the racial groups have a history of scoring differently on the test for reasons of test bias, stereotype threat, societal discrimination, and the like. In order to reproduce the same overall scoring pattern on the new test, items that favor the lower scoring minority group will be discarded, but items that favor the higher scoring majority group will be retained. To do otherwise would be to reduce the internal consistency of the test, as all items must be pointing in the same direction. n11 

n11 As Mr. Rosner, an expert on test preparation, testified, this approach can and does select test questions that meet test specifications and criteria even when the test maker itself has identified the wrong answer, not the correct answer. Expert Report of Jay Rosner, reprinted in 12 Berkeley La Raza L.J. 377, 379 (2001) (hereinafter Rosner Expert Report) 

Once pretested items are selected, a statistical procedure designed to identify items that function differently for two groups is employed--but only after comparing applicants with similar overall scores. Because this procedure, called Differential Item Functioning (DIF), necessarily assumes that  [*19]  other items are unbiased, it can only identify items that are grossly unfair to one or another group, but will be unable to notice subtle, systematic bias in favor of the already favored majority. Items are also reviewed for sensitivity to various groups, so that offensive stereotypes are not included in the test. However, if an offensive item is identified, it is either modified or replaced--with an item of similar statistical characteristics. Thus it is not the selection of one individual item that creates the problem, but the collection of an entire test of items that depend on each other for internally consistent results that produces an enlarged discriminatory impact. This problem is not unique to the SAT or the LSAT, but is a problem associated with any norm-referenced multiple-choice test. See, e.g., Rosner Expert Report, supra, 12 Berkeley La Raza L.J. at 380-81; White Expert Report, supra, 12 Berkeley La Raza L.J. at 412-15, 8 Transcript, Feb. 6, 2001, at 45:25-46:6 (Shapiro). 

The difference between grades and admission tests can be attributed to their separate tasks. Grades are intended to reflect academic performance in the classroom, on teacher-developed tests, and in out-of-class projects in a variety of specific fields of knowledge. Tests such as the SAT and LSAT claim not to presuppose any prior field of study, but are intended to draw upon a "curriculum free" group of largely multiple-choice questions to predict future performance in a broadly defined academic domain. See 8 Transcript, Feb. 6, 2001, at 32:10-17 (Shapiro). Individual course grades can diverge from each other without diluting the value of the summation across a number of grades, but individual items may not diverge from the overall pattern of internal consistency without simultaneously reducing the ability of the overall test to predict performance. When a small racial group that has performed poorly on the test participates in a pretest, it risks validating long-standing prejudices with seeming scientific prediction. Test-makers who have  [*20]  confronted this association between average test scores and different racial groups have suggested that a test may be considered more useful than biased when it correlates more with the criterion to be predicted, such as first-year law school grades, than it does with racial identity. Measured against this standard, the LSAT proves to be biased, as it correlates more with racial membership than it does with first-year law school grades. David M. White, An Investigation into the Validity and Cultural Bias of the Law School Admission Test, in Towards a Diversified Legal Profession 66, 202 (David White ed., 1981) (citing Robert Schrader & Barbara Pitcher, Predicting Law School Grades for Black American Law Students, 2 Law School Admission Council Research 450 (1973)). 

For these reasons, admissions offices must be able to consider the applicant's race or ethnic background in order to compensate for the internal bias of standardized tests and standardized testing and ensure applicants of color equal treatment. 

B. External Biases and Stereotype Threat in Standardized Testing 

There are significant external factors as well that cause African-American, Hispanic, and Native-American students to perform less well than other groups on standardized tests, such that the SAT and LSAT are not race-neutral measures of "merit". The pervasive stereotypes of racial inferiority identified generation after generation in cases such as Brown v. Board of Education, 347 U.S. 483 (1954) and United States v. Fordice, 505 U.S. 717 (1992), artificially suppress test scores of students of color--not their underlying merit being measured, just their scores on the standardized tests. 

Professor Steele undertook to test the existence of "stereotype threat" with a simple and compelling experiment under controlled conditions. Not only did he discover and  [*21]  demonstrate the external (to the test) and adverse effects of racial bias, but he discovered that those effects became more severe the more qualified the applicant, such that those minority applicants most likely to qualify for admission to a prestigious graduate school like the University of Michigan's Law School were, at the same time, most likely to exhibit the most severe effects of stereotype threat and artificially depressed test scores. 

As Professor Steele explained below:
[We] asked Black and White Stanford students into our laboratory and, one at a time, gave them a very difficult 30-minute verbal test, the items of which came from the advanced Graduate Record Examination in literature. The bulk of these students were sophomores, which meant that the test would be difficult for them--precisely the feature that we reasoned would make this simple testing situation different for our Black participants than for our White participants. We told each student that we were testing ability. 

Black students performed dramatically worse than White students on the test. As we had statistically equated both groups on ability level, the differences in performance were not because the Black students had weaker skills than the White students. Something else was involved. Before we could confirm that that "something else" was stereotype threat, we had to control for the possibility that the Black students performed worse than the White students because they were less motivated or because their skills could be somehow less easily extrapolated to the advanced material of this test. We concluded that if stereotype threat and not something about these students themselves had caused their poorer test performance, then doing something that would reduce this threat during the test should allow their performance to improve, to go up to  [*22]  the level of equally capable White students. We devised a simple way to test this: We presented another group of Black and White sophomores, again statistically equated on ability level, the same test we had used before--not as a test of ability, but as a "problem-solving" task that had nothing to do with ability. This made the stereotype about Blacks' ability irrelevant to their performance on the task since, ostensibly, the task did not measure ability. A simple instruction, yes, but it profoundly changed the meaning of the situation. It told Black participants that the racial stereotype about their ability was irrelevant to their performance on this particular task. . . . 

As a result, Black students' performance on this test matched the performance of equally qualified Whites. . . .
  
Steele Expert Report, supra, 5 Mich. J. Race & L. at 444-45. n12 

n12 Similarly, the evidence also indicates that, because of the prevalent stereotypes about minorities and standardized tests, students of color enter these tests with greater feelings of avoidance. The majority of white students take the LSAT in the earlier administration, but the majority of African American students wait until the second and last administration of each year when there is no second opportunity for improvement. Rosner Expert Report, supra, 12 Berkeley La Raza L.J. at 384. 

These effects of pervasive racial stereotyping upon standardized testing affect the most qualified students of color most, because the most qualified students of color care most about scores and consequences of the high-stakes standardized test for admission to the graduate school of their choice. "We have also discovered that the detrimental effect of stereotype threat on test performance is greatest for those students who are the most invested in doing well on the test. As an intimidation, one might expect that it would affect the  [*23]  weakest students most. But this is not what happens. Across our research, stereotype threat most impaired students who were the most identified with achievement, those who were also the most skilled, motivated, and confident--the academic vanguard of the group more than the academic rearguard." Id., at 446. n13 Contrary to the critical assumption Petitioner asks this Court to make as a predicate to overruling Bakke and ending careful affirmative action programs in education to compensate for a history of racial and gender discrimination in education, n14 the gaps on high-stakes standardized tests like  [*24]  the LSAT do not reflect that the minorities being admitted are less qualified, but that they are affected more by the very racial stereotypes this country still must overcome. See, e.g., White Expert Report, supra, 12 Berkeley La Raza L.J. at 405-06, quoted in Pet. App. at 269a, 137 F. Supp. 2d at 861. 

n13 Professor Steele further confirmed these findings by testing the converse. Most research focuses on replicating the stereotypes, and so even Professor Steele's earlier experiments had examined students associated with the aspect of the test where their scores were low--for example, Black students and verbal skills, or women students and math skills. But a "person has to care about a domain in order to be disturbed by the prospect of being stereotyped in it". Id., at 446. When Professor Steele did comparative tests with participants who were less identified by stereotype with the domains being tested, they did not show any independent effect of stereotype threat (although they still might not have performed well). "Now make no mistake, these disidentified students did not perform well on the tests. Like anyone who does not care, they would start the test, discover its difficulty, stop trying very hard and get a lower score. But their performance did not differ depending on whether they were at risk of being judged stereotypically--their performance was the same regardless of whether they had been told it was their ability we were testing." Id., at 446. 

n14 As its first finding of fact and conclusion of law, the district court found that "First, there is no question about the long and tragic history of race discrimination in this country." Pet. App. at 274a, 137 F. Supp. 2d at 863. "The court has made its findings on the factual issues relevant to this inquiry and, as noted above, the court concludes that the comparatively lower grades and test scores of underrepresented minorities is attributable, at least in part, to general, societal racial discrimination against these groups. While the court may agree with some of the factual underpinnings of the intervenors' argument, the legal conclusion they draw therefrom is flawed both as a matter of logic and as a matter of constitutional law." Pet. App. at 284a-285a, 137 F. Supp. 2d at 868. 

The evidence went unrefuted at trial, and this research has been reviewed in numerous other psychological studies and widely accepted by peers in the academic community. See, e.g., Clark D. Cunningham, Glenn C. Loury & John D. Skrentny, Passing Strict Scrutiny: Using Social Science To Design Affirmative Action Programs, 90 Geo. L.J. 835, 839 & n.11 (2002) ("Other researchers have replicated these results and the stereotype threat theory is now widely accepted within the field of psychology."). It has been confirmed not only for African-Americans, but for Hispanics and women as well. E.g., Patricia M. Gonzales, Hart Blanton & Kevin J. Williams, The Effects of Stereotype Threat and Double-Minority Status on the Test Performance of Latino Women, Personality & Soc. Psychol. Bulletin 659 (2002). 

The "numbers" on the LSAT which Petitioner asks this Court to ratify as the neutral measure of "merit" instead measure, for students of color, the effects of the very stereotypes perpetuated by Petitioner's claim and argument that minorities have less merit and less entitlement to admission because they have lower scores. It is the very stereotype Amicus Curiae FairTest urges this Court not to perpetuate. Only narrowly-tailored affirmative action, such as that practiced by the University of Michigan's Law School, to compensate for and neutralize this racial bias, allows a graduate school's admission office to ensure that all applicants are treated equally as similarly situated individuals. n15 

n15 Thus, the discussion in the court of appeals' opinions below, about whether Bakke does or does not require standardized test scores or grade-point averages to be equivalent before one considers race or ethnicity as a factor in admissions decisions, becomes unnecessary. See Pet. App. at 30a-32a, 288 F.3d at 748-49; id., at 131a-140a, 288 F.3d at 796-800 (Boggs, J., dissenting); id., at 175a-176a, 288 F.3d at 817-18 (Gilman, J., dissenting). The empirical studies have controlled for same undergraduate grade-point average, same elite institution, even the same major, and shown the bias in the SAT's and LSAT's testing. Correcting that bias, the record and expert testimony indicate, would allow the students to have equivalent standardized test scores as well as equivalent grade-point averages. 

 [*25]  C. Unequal Access to Test Preparation 

Not only are the admissions tests subject to internal biases, and not only is standardized testing subject to external biases such as stereotype threat, but access to test preparation courses to improve test scores and perhaps compensate for these biases is itself biased and not equally available. 

Mr. Jay Rosner is an expert in establishing, designing, and monitoring admission test preparation courses to underrepresented minority and low-income students, affiliated with the nation's largest SAT test preparation company. He provided expert testimony on the bias in access to test preparation for both the SAT and the LSAT. Rosner Expert Report, supra, 12 Berkeley La Raza L.J. at 377-78. The district court found this to be "important testimony". Pet. App. at 268a, 137 F. Supp. 2d at 860. 

As the district court noted, the evidence demonstrates that test preparation courses "generally improve one's LSAT score by approximately seven points". Pet. App. at 268a, 137 F. Supp. 2d at 860; see Rosner Expert Report, supra, 12 Berkeley La Raza L.J. at 384-85. This is a substantial increase when compared with the average differences in LSAT scores between minority applicants and White applicants, ranging from -4.0 points below for Native Americans, to -6.8 points below for Hispanics, to -9.2 points  [*26]  below for African Americans. Pet. App. at 269a, 137 F. Supp. 2d at 861. 

Minority students' unequal access to test preparation courses is another very significant bias. The test preparation courses are expensive; the most obvious bias is the diminished ability to afford the $ 800-$ 1,000 that each student must pay for the course. Rosner Expert Report, supra, 12 Berkeley La Raza L.J. at 384-85. In addition, students of color are far less aware of the benefits of taking test preparation courses. Pet. App. at 268a, 137 F. Supp. 2d at 860-61. Consequently, "the vast majority of the students who take an LSAT preparation course are white, and . . . this fact accounts for some of the test-score gap between minority and non-minority test-takers." Pet. App. at 268a, 137 F. Supp. 2d at 861. 

III. THE UNIVERSITY OF MICHIGAN LAW SCHOOL'S POLICY CONSTITUTES A NECESSARY AND CONSTITUTIONAL REMEDY IN THIS CASE. 

The University of Michigan Law School, like law schools across the nation, gives considerable weight to undergraduate grade-point averages and LSAT scores. As Amicus Curiae FairTest has explained above, these measures are subject to racial bias, of both internal and external origins, and a policy of affirmative, compensatory action is necessary in order to correct for that racial bias and afford applicants of color equal treatment. The University of Michigan Law School has developed one such careful and narrowly tailored policy, and that policy should be upheld. Conversely, a conclusion that the University of Michigan Law School's policy were unconstitutional would leave unaddressed the fact of this racial bias and the consequence that applicants of color would be denied equal treatment because consideration of their merit and promise in graduate school would remain substantially biased. 

 [*27]  The district court acknowledged the significant and sufficient error inherent in the very measures Petitioner cites to this Court to establish "merit" and the presence or absence of equal protection, stating that "decreasing the emphasis for all applicants on undergraduate GPA and LSAT scores" would be a narrowly-tailored alternative. Pet. App. at 251a, 137 F. Supp. 2d at 852-53; id., at 288a, 137 F. Supp. 2d at 870 ("One such solution may be to relax, or even eliminate, reliance on the LSAT. The evidence presented at trial indicated that the LSAT predicts law school grades rather poorly (with a correlation of only 10-20%) and that it does not predict success in the legal profession at all. If, as its admissions policy states, the law school seeks students who 'have substantial promise for success in law school' and 'a strong likelihood of succeeding in the practice of law,' one must wonder why the law school concerns itself at all with an applicant's LSAT score."); id., at 290a, 137 F. Supp. 2d at 871 ("Another solution may be for the law school to relax its reliance on undergraduate GPA. The law school's admissions policy acknowledges that, even in combination, the LSAT score and undergraduate GPA are 'far from perfect' predictors of success in law school. In fact, the policy asserts that the correlation between the index score and first-year law school grades is merely 27%. . . . The policy also notes the obvious fact that high undergraduate grades may overstate an applicant's academic achievements or promise, and that low grades may understate them."). 

In an environment where state and federal governments are only increasing the prevalence and pressure of high-stakes standardized testing throughout education, the district court's suggestion in dictum, that law schools might just stop using the LSAT, rings hollow, for it is clearly not realistic in the foreseeable future. Moreover, as long as ubiquitous tests such as the SAT and LSAT remain unable to eliminate the biases that perpetuate the racial and gender gaps in admissions test  [*28]  scores, it is incumbent upon test-users (as the test-makers themselves acknowledge) not to take the test scores at face value and not to equate them with "merit". 

The remedy for internal and external racial bias in standardized testing in this case is a careful, narrowly tailored policy of affirmative action where the applicant's racial or ethnic background may be considered to correct for and compensate for that bias and thus afford both applicants of color, alongside White applicants, the equal protection of the laws. 

In Brown v. Board of Education, this Court reviewed the psychological knowledge of the time and expressly examined the factors that deprive children of minority groups of equal educational opportunities. 347 U.S. 483, 493-94 & n.11 (1954), judgment entered, 349 U.S. 294 (1955). The Court examined "tangible" factors such as physical plant; and it examined the intangible factors, such as segregation, or racial bias, that deprive minority children of equal educational opportunities. Id., at 493. It examined "those qualities which are incapable of objective measurement but which make for greatness in a law school". Id., at 493 (quoting Sweatt v. Painter, 339 U.S. 629, 634 (1950)). The racial bias in standardized tests such as the SAT and LSAT has been objectively measured. As in Brown, the racial bias in standardized tests and the stereotype threat adversely affecting the most academically promising applicants of color, perpetuates "a feeling of inferiority as to their status in the community that may affect their hearts and minds in a way unlikely ever to be undone". Id., at 494. As in Brown, the failure to correct for this racial bias through affirmative and compensatory consideration of the applicant's race or ethnicity would deprive them of equal treatment. See id., at 495. 

This is not a case where a race-conscious admission policy is being used to admit less qualified candidates. Instead, this  [*29]  case poses the simple question of whether a university may consider the applicant's race or ethnic background as a factor to correct for biases in standardized admissions tests and testing and admit equally qualified applicants of color. In the case of a narrowly tailored affirmative action program such as the one at issue here, the answer to that question should be in the affirmative. 

CONCLUSION 

Given the fact of racial bias and other significant measurement errors in the SAT and LSAT, as well as significant racial differences in access to preparation for these tests, requiring compensatory consideration of the applicant's racial or ethnic background, FairTest respectfully submits that an affirmative action policy such as that of the University of Michigan Law School here is equitable and constitutional. Test scores do not equate with "merit". The judgment of the United States Court of Appeals for the Sixth Circuit below should be affirmed. 
