## SHOULD IMPLEMENT PRESERVATION OF URLs

#' simple cleaning of text before processing
#' 
#' \code{clean} removes punctuation and digits from text, using the regex 
#' character classes for punctuation and digits. \code{clean} uses the standard R
#' function \code{tolower} to convert the text to lower case. Each of these 
#' steps is optional, but switched on by default, so for example, to remove 
#' punctuation and convert to lower, but keep digits, the command would be: 
#' \code{clean(mytexts, removeDigits=FALSE)}
#' @rdname clean
#' @param x The object to be cleaned. Can be either a character vector or a 
#'   corpus object. If x is a corpus, \code{clean} returns a copy of the x with 
#'   the texts cleaned.
#' @param removeDigits remove numbers if \code{TRUE}
#' @param removePunct remove punctuation if \code{TRUE}
#' @param lower convert text to lower case \code{TRUE}
#' @param twitter if \code{TRUE}, do not remove \code{@@} or \code{#}
#' @param additional additional characters to remove (\link[=regex]{regular expression})
#' @param ... additional parameters
#' @return A character vector equal in length to the original texts, after cleaning.
#' @examples
#' clean("This is 1 sentence with 2.0 numbers in it, and one comma.", removeDigits=FALSE)
#' clean("This is 1 sentence with 2.0 numbers in it, and one comma.", lower=FALSE)
#' clean("We are his Beliebers, and him is #ourjustin @@justinbieber we love u", twitter=TRUE)
#' clean("Collocations can be represented as inheritance_tax using the _ character.")
#' clean("But under_scores can be removed using the additional argument.", additional="[_]")
#' 
#' # for a vector of texts
#' clean(c("This is 1 sentence with 2.0 numbers in it, and one comma.", 
#'         "$1.2 billion was spent on text analysis in 2014."))
#' @export
clean <- function(x, ...) {
    UseMethod("clean")
}


#' @rdname clean
#' @export
clean.character <- function(x, removeDigits=TRUE, removePunct=TRUE, lower=TRUE, 
                            additional=NULL, twitter=TRUE, ...) {
    if (!(removeDigits | removePunct | lower) & is.null(additional)) {
        warning("  clean: text unchanged")
    }
    if (removePunct) {
        # use "negative lookahead" to keep Twitter symbols, always keep "_"
        # remove other punctuation from POSIX [:punct:]
        remove <- paste("(?![",
                        ifelse(twitter, "@#_", "_"),
                        "])[[:punct:]]", 
                        ifelse(!is.null(additional), paste("|", additional, sep=""), ""),
                        sep="")
       x <- gsub(remove, "", x, perl=TRUE)
    }
    
    if (removeDigits) 
        x <- gsub("[[:digit:]]", "", x)
    if (lower) 
        x <- tolower(x)
    
#     if (!is.null(additional))
#         x <- gsub(additional, "", x)
    
    # convert 2+ multiple whitespaces into one
    x <- gsub("\\s{2,}", " ", x, perl=TRUE)
    # remove leading and trailing whitespace and return
    gsub("^ +| +$", "", x)
}


#' @rdname clean
#' @export
clean.corpus <- function(x, removeDigits=TRUE, removePunct=TRUE, lower=TRUE, 
                         additional=NULL, twitter=TRUE, ...) {
    clean(texts(x), removeDigits=removeDigits, removePunct=removePunct, lower=lower, 
          additional=additional, ...)
}

#' stem words
#' 
#' Apply a stemmer to words.  This is a wrapper to \link[SnowballC]{wordStem} 
#' designed to allow this function to be called without loading the entire 
#' \pkg{SnowballC} package.  \link[SnowballC]{wordStem}  uses Dr. Martin 
#' Porter's stemming algorithm and the C libstemmer library generated by 
#' Snowball.
#' @param words a character vector of words whose stems are to be extracted.
#' @param language the name of a recognized language, as returned by 
#'   getStemLanguages, or a two- or three-letter ISO-639 code corresponding to 
#'   one of these languages (see references for the list of codes)
#' @return A character vector with as many elements as there are in the input
#'   vector with the corresponding elements being the stem of the word. Elements
#'   of the vector are converted to UTF-8 encoding before the stemming is
#'   performed, and the returned elements are marked as such when they contain
#'   non-ASCII characters.
#' @seealso \link[SnowballC]{wordStem}; \url{http://snowball.tartarus.org/}.
#' @export
#' @examples
#' # Simple example
#' wordstem(c("win", "winning", "winner"))
wordstem <- function(words, language = "porter") {
    SnowballC::wordStem(words, language)
}

# rdname wordstem
# export
#  from https://sites.google.com/site/motazsite/arabic/arlightstemmerlucene.jar
#  source: https://sites.google.com/site/motazsite/arabic/arlightstemmerlucene-src.7z
# wordstemArabic <- function(x) {
#     require(rJava)
#     .jinit("java/ArLightStemmerLucene.jar")
#     hjw <- .jnew("ArLightStemmerLucene")     # create instance of ArLightStemmerLucene class
#     out <- .jcall(hjw, "S", "main", x)  # invoke sayHello method
#     return(out)
# }
# 
